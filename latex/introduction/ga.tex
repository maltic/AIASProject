Genetic algorithms as defined in \cite{ga} are a class of evolutionary algorithms which use a population of collections of descriptors which describe how they are characterised in the problem domain. As such each descriptor is often called a gene, a collection of genes is often called a genome or genotype, and the characterisation of the genotype in the problem domain is called a phenotype. Every member of the population has a `fitness' which is used to find optimal solutions in the problem domain. Phenotypes which are more optimal will have a greater fitness. Members of the population interact using genetic operators such as mutation and crossover to produce new members which may or may not be more optimal, i.e. have greater fitness. The rate at which these operators occur balance exploitation vs. exploration.

Genetic algorithms are used in two different ways in this project. The first is to train artificial neural nets in Neuroevolution, and to learn the best combination of predefined strategies to combat an enemy. The other application is to use genetic algorithms to learn the best combination of predefined strategies to combat an enemy in contrast to Ant Colony Optimisation.

There are many different types of genes. Common gene representations are bits, integers, and floating-point numbers. These can be used to represent many different properties; such as membership, a class, or a weight in a graph (respectively). Therefore an entire network can be represented by a genotype of a collection of floating-point numbers, where each floating point number is a weight on an edge, where the particular edge is identified by the location of the floating-point number in the genotype.


When using a genetic algorithm, the user needs to define genes, genotypes, phenotypes and a fitness which describes how fit each phenotype is in the problem domain. 



At each iteration of the algorithm in which the population is evolved genetic operators are applied. The genetic operators used are:
\begin{itemize}
\item Selection;
\item Elitism;
\item Crossover; and 
\item Mutation.
\end{itemize}

Elitism is used in order to increase the rate at which the algorithm converges. It works by taking a fixed percentage of the population which are the fittest members into the next generation. This also ensures that the fittest solution found at any iteration is in the final population. It improves the rate of covergence because the elite members are more likely to be chosen in future iterations for crossover and mutation; and so the genetic information from the elite members always survives and can spread to new members. Ideally, the genes which are transferred to new members are responsible for their high fitness and so new members also have similar fitness as the elite members; thus converging quickly.

Selection is a method for selecting members for the crossover and mutation operators. Two types are investigated, Tournament and Truncation selection.

Selection methods do not produce new members but they are used to select members for crossover and mutation. A genetic algorithm exploits the current population by tending to select members which already have a high fitness. Therefore selection operators tend to select fitter members. It is also important to increase diversity and exploration. This is done by probabilistically selecting members such that fitter members are more likely to be selected, but weaker members also have a chance to be selected. Tournament selection allows this because the fittest member selected for the small tournament may not be the same as the fittest member of the population. Small tournament sizes favour exploration; increasing divesity.

The other selection operator used was Truncation selection. Truncation selection takes a certain percentage (e.g. 40\%) of the fittest members of the population as potential parents. Members are selected uniformly with replacement from the truncated population for both mutation and crossover. The uniform selection allows the weaker members of the truncated population to be selected increasing diversity; but the truncated population eliminiates potential very bad choices increasing the rate of convergence.

Mutation is an operator which allows for new genetic information which may not already exist within the population to be introduced into the population. Mutation works by randomly changing a collection of genes within a genotype. There are different types of mutation, for example reselection of a gene (uniformly or by another probability distribution); scaling a gene by some amount especially if it is a number; or a random walk in a graph that has been imposed on the potential genes. As such new genes can be selected which may improve the current fitness. Mutation is required because it allows genetic algorithms to escape local optima. If the algorithm converges prematurely because of a lack of genetic diversity, then mutation can increase the amount of genetic diversity allowing the genetic algorithm to further explore the problem domain.


Crossover (or recombination) is an operator which combines two (or more) selected members of the population into a collection of `offspring' which use genes from the `parents'. There are many different types of crossover operations. A common crossover operation for strings of genes is one-point crossover where a point is uniformly chosen in the genotype and two children are created by using the first half and the second half of each parent. Multiple crossover points can also be used. 
If a genetic algorithm lacks genetic diversity then they converge to a local optima because there isn't enough distinctive genes to change the fitness and the genotypes of the members of the population. Methods are often implemented to guarantee a specific level of diversity. Such methods are related multimodal optimization where the population does not focus toward a single optima, rather, tries to sustain many optima. 
