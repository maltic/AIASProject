\subsubsection{Aim}
The aim of this experiment is to test the Neuroevolution implementation and to determine if it is appropriate for learning a general Robocode strategy from scratch.

\subsubsection{Experimental Hypothesis}
It is hypothesised using a pure holistic Neuroevolution approach to learning a general strategy for a Robocode robot is achievable.

\subsubsection{Methodology and Rationale}

\begin{description}
\item Neural Network Topology \hfill \\
Neuroevolution requires a specified topology of the network. Preliminary experimentation revealed the topology defined by the vector $<13, 15, 7, 5>$ was effective for learning without taking too long to learn. There are a total of $13 \times 15 + 15 \times 7 + 7 \times 5 = 335$ weights. It is expected such a topology allows for the inputs to be expanded upon and then combined slowly to the outputs.

\item Number of Populations and Population Size \hfill \\
Neuroevolution was done using 3 populations containing 32 individuals each. Evaluating the fitness is the most significant time expenditure and therefore the total number of individuals is kept fairly small. 

\item Running the Algorithm \hfill \\
The algorithm was run overnight because it ran so slowly, and the presented results show fitness at every tenth generation to help remove noise.

\item Fitness \hfill \\
Unless otherwise stated, the fitness function used was the same as Equation \ref{eqn:fitness}. The score is the total score after 40 rounds. 


\item Neuroevolution Genetic Algorithm Parameters \hfill \\
The parameters set for the GA used for training were found by trial and error. A truncation factor of 50\% was used. Anything less tended to mean that the algorithm converged on suboptimal solutions too quickly. We had the crossover rate was set to 35\% and the mutation rate was set to 60\%, and therefore a 5\% chance of adding a new random individual in place of breeding an old one.

The crossover weight was attempted to be set higher; however this lead to much slower rates of convergence. Setting it too low also presented the same problem. This is likely due to good innovations -- which can be shared between different populations -- were never able to mix with other good but incomplete solutions.

Having a small chance of introducing new individuals made the average fitness appear more noisy, but also seemed to prevent premature convergence.



\end{description}
